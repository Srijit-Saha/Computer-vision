# -*- coding: utf-8 -*-
"""cv_assign_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WXProLdW0_B8mdztkjuB13aqoPjfJNYw
"""

import numpy as np
import matplotlib.pyplot as plt
import cv2
import glob
plt.rcParams['figure.figsize'] = (20, 12)

!rm *.jpeg
!gdown --id 1J5PqqKs0VaE8KIC6GMzDiR9zyzkAkxBa
!unzip CVpics.zip

objp = np.zeros((7*7,3), np.float32)
objp[:,:2] = np.mgrid[0:175:25,0:168:24].T.reshape(-1,2)
print('Object Points: ', objp, sep='\n')

# Arrays to store object points and image points from all the images.
objpoints = [] # 3d point in real world space
imgpoints = [] # 2d points in image plane.

# Reading images
images = glob.glob('*.jpeg')
# Sorting images according to the number
images.sort(key=lambda x: int(x.split('.')[0][-2:-1]))

# Defining termination criteria
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)

fig, ax = plt.subplots(2,5)
for i in ax.flatten():
  i.axis('off')

for i, fname in enumerate(images):
    img = cv2.imread(fname) # Capture frame-by-frame
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Find the chess board corners
    ret, corners = cv2.findChessboardCorners(gray, (7,7), None)
    # If found, add object points, image points (after refining them)
    if ret:
        objpoints.append(objp)
        corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)
        imgpoints.append(corners2)
        # Draw and display the corners
        img = cv2.drawChessboardCorners(img, (7,7), corners2, ret)
        ax[i//5,i%5].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        ax[i//5,i%5].set_title(fname)

images

# calibration
ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)

# Rounding off the matrix and distortion coefficients
np.set_printoptions(precision=4, suppress=True)

# Displaying camera matrix and distortion paremeters
print("Intrinsic Camera Matrix:",mtx, sep='\n', end='\n\n')
print("Lens Distortion Parameters:",dist, sep='\n')

# Re-Projection Error
mean_error = 0
for i in range(len(objpoints)):
    imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)
    error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2)/len(imgpoints2)
    mean_error += error
print( "total error: {}".format(mean_error/len(objpoints)) )

# Undistorted Image
img = cv2.imread(images[0])
h,w = img.shape[:2]
newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))

# undistort
dst = cv2.undistort(img, mtx, dist, None, newcameramtx)
# crop the image
x, y, w, h = roi
dst = dst[y:y+h, x:x+w]
plt.axis('off')
plt.imshow(cv2.cvtColor(dst, cv2.COLOR_BGR2RGB));

!rm *.jpg
!gdown --id 1FYCXIzwR3OlVSO4X0JrFIF0FCbjIB026
!unzip dotgridpattern.zip

# Setting up Blob Detector for the circles

# Setup SimpleBlobDetector parameters.
blobParams = cv2.SimpleBlobDetector_Params()

# Change thresholds
blobParams.minThreshold = 8
blobParams.maxThreshold = 255

# Filter by Area.
blobParams.filterByArea = True
blobParams.minArea = 30
blobParams.maxArea = 2500

# Filter by Circularity
blobParams.filterByCircularity = True
blobParams.minCircularity = 0.1

# Filter by Convexity
blobParams.filterByConvexity = True
blobParams.minConvexity = 0.87

# Filter by Inertia
blobParams.filterByInertia = True
blobParams.minInertiaRatio = 0.01
blobParams.minDistBetweenBlobs = 2

# Create a detector with the parameters
blobDetector = cv2.SimpleBlobDetector_create(blobParams)

# Preparing object points
# The distance between the centres of the blobs is 2.2cm
objp = np.zeros((10*10,3), np.float32)
objp[:,:2] = np.mgrid[0:220:22,0:220:22].T.reshape(-1,2)

print('Object Points: ', objp, sep='\n')

# Arrays to store object points and image points from all the images.
objpoints = [] # 3d point in real world space
imgpoints = [] # 2d points in image plane.

# Reading images
images = glob.glob('dotgridpattern/*.jpeg')
# Sorting images according to the number
images.sort(key=lambda x: int(x.split('/')[1].split('.')[0]))

# Defining termination criteria
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)

# Counter for images where corners were detected
found = 0

fig, ax = plt.subplots(3,5)
for i in ax.flatten():
  i.axis('off')
for i, fname in enumerate(images):
    img = cv2.imread(fname) # Capture frame by frame
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Detecting blobs
    keypoints = blobDetector.detect(img)
    # Draw detected blobs as red circles
    im_with_keypoints = cv2.drawKeypoints(img, keypoints, np.array([]), (0,255,0),
                                          cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
    im_with_keypoints_gray = cv2.cvtColor(im_with_keypoints, cv2.COLOR_BGR2GRAY)


    # Find the chess board corners
    ret, corners = cv2.findCirclesGrid(im_with_keypoints_gray, (10,10), None,
                                      blobDetector = blobDetector)

    # If found, add object points, image points (after refining them)
    if ret:
        objpoints.append(objp)
        corners2 = cv2.cornerSubPix(im_with_keypoints_gray, corners,
                                    (11,11), (-1,-1), criteria)
        imgpoints.append(corners2)
        # Draw and display the corners
        img = cv2.drawChessboardCorners(img, (10,10), corners2, ret)
        #gray = cv2.drawChessboardCorners(gray, (7,7), corners2, ret)
        ax[i//5,i%5].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        #ax[i//5,i%5].imshow(img, interpolation='nearest')
        ax[i//5,i%5].set_title(fname)

        found+=1

print('Number of images retained during blob detection: ',found)

# calibration
ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, im_with_keypoints_gray.shape[::-1], None, None)

# Rounding off the matrix and distortion coefficients
np.set_printoptions(precision=4, suppress=True)

# Displaying camera matrix and distortion paremeters
print("Intrinsic Camera Matrix:",mtx, sep='\n', end='\n\n')
print("Lens Distortion Parameters:",dist, sep='\n')

# Undistorted Image
img = cv2.imread(images[0])
h,w = img.shape[:2]
newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))

# undistort
dst = cv2.undistort(img, mtx, dist, None, newcameramtx)
# crop the image
x, y, w, h = roi
dst = dst[y:y+h, x:x+w]
plt.axis('off')
plt.imshow(cv2.cvtColor(dst, cv2.COLOR_BGR2RGB));

lrs=[1,2,3,4,5,6]
print(lrs[0:-1])